{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sriVW8XJn8cl"
      },
      "source": [
        "# Fooocus Colab\n",
        "\n",
        "This scipt is not perfect but usable.. at least it woks on my machine ðŸ¤“"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv8objfCxDaF"
      },
      "source": [
        "## Init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "import yaml\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "config = {}\n",
        "output_path = \"/content/Fooocus/output\"\n",
        "civitai_api_key = \"\"\n",
        "\n",
        "def mount_drive():\n",
        "    mount_path = \"/content/drive\"\n",
        "    if not os.path.exists(mount_path):\n",
        "        drive.mount(mount_path)\n",
        "\n",
        "def install_requerements():\n",
        "    if not os.path.exists(\"/content/Fooocus\"):\n",
        "        !pip install -q civitdl pygit2==1.12.2\n",
        "        %cd /content\n",
        "        !git clone https://github.com/lllyasviel/Fooocus.git\n",
        "        %cd /content/Fooocus\n",
        "        !mv *.ogg notification.ogg\n",
        "\n",
        "def write_to_file(config: str | dict | list, base_config_file: str, overwrite: bool = False):\n",
        "    # Append file if file exists\n",
        "    if os.path.isfile(base_config_file) and not overwrite:\n",
        "        base_config = json.load(open(base_config_file, \"r\"))\n",
        "        if isinstance(base_config, list) and isinstance(config, list):\n",
        "            config = base_config + config\n",
        "        elif isinstance(base_config, dict) and isinstance(config, dict):\n",
        "            config = { **base_config, **config }\n",
        "    # Write file\n",
        "    out_file = open(base_config_file, \"w\")\n",
        "    if isinstance(config, str):         # write string\n",
        "        out_file.write(config)\n",
        "    else:                               # write dict / list\n",
        "        json.dump(config, out_file, indent=4)\n",
        "\n",
        "def download(url: str, destination: str):\n",
        "    global civitai_api_key\n",
        "    if url.startswith(\"https://civitai.com/models/\"):\n",
        "        civitdl_params = f\"{destination} --api-key {civitai_api_key} --no-model-overwrite\"\n",
        "        !civitdl {url} {civitdl_params}\n",
        "    else:\n",
        "        !wget --content-disposition -nc -P {destination} {url}\n",
        "\n",
        "def batch_download(links: list, destination: str):\n",
        "    if not isinstance(links, list) or len(links) == 0:\n",
        "        return\n",
        "    print(f\"\\n[Batch Download] {destination} of {len(links)} links\")\n",
        "    for key, item in links.items():\n",
        "        print(f\"Downloading : {key} to {destination}\")\n",
        "        download(item, destination)\n",
        "\n",
        "def dict_print(obj: dict):\n",
        "    print(json.dumps(obj, sort_keys=True, indent=4))\n",
        "\n",
        "def run_ngrok_service(ngrok_token: str):\n",
        "    !pip install pyngrok\n",
        "    from pyngrok import ngrok, conf\n",
        "    config = conf.PyngrokConfig(auth_token=ngrok_token)\n",
        "    conn = ngrok.connect(7865, pyngrok_config=config, bind_tls=True)\n",
        "    print(conn.public_url)\n",
        "\n",
        "def copy_assets(from_dir: str, to_dir: str):\n",
        "    print(f\"Copy file {from_dir} to {to_dir}\")\n",
        "    !cp -r -n {from_dir} {to_dir}\n",
        "\n",
        "def import_config():\n",
        "    uploaded = files.upload()\n",
        "    result = {}\n",
        "    for file_name in uploaded.keys():\n",
        "        try:\n",
        "            result = yaml.safe_load(open(file_name))\n",
        "        except yaml.YAMLError as exc:\n",
        "            print(exc)\n",
        "        !rm {file_name}\n",
        "        return result\n",
        "\n",
        "def generate_preset(preset: dict, file_name: str):\n",
        "    preset_dir = \"/content/Fooocus/presets/\"\n",
        "    if \"default_model\" not in preset:\n",
        "        model_files = glob.glob(f\"/content/Fooocus/models/checkpoints/**.safetensors\")\n",
        "        preset[\"default_model\"] = model_files[0]\n",
        "    print(f\"[Generate Peset] {file_name}\")\n",
        "    write_to_file(preset, preset_dir + file_name)\n",
        "\n",
        "def generate_style(style: dict, file_name: str):\n",
        "    style_dir = \"/content/Fooocus/sdxl_styles/\"\n",
        "    print(f\"[Generate Style] {file_name} of {len(style)} Styles\")\n",
        "    write_to_file(style, style_dir + file_name, overwrite=True)\n",
        "\n",
        "def generate_wildcard(wildcard: str, file_name: str):\n",
        "    wildcard_dir = \"/content/Fooocus/wildcards/\"\n",
        "    print(f\"[Generate Wildcard] {file_name} of {len(str(wildcard).splitlines())} Lines\")\n",
        "    write_to_file(wildcard, wildcard_dir + file_name, overwrite=True)\n",
        "\n",
        "def models_storage_stats():\n",
        "    print(\"\\n[Models Storage Stats]\")\n",
        "    !du -ms /content/Fooocus/models/checkpoints\n",
        "    !du -ms /content/Fooocus/models/loras\n",
        "    !du -ms /content/Fooocus/models/embeddings\n",
        "\n",
        "def delete_unused_files(unused_files: list):\n",
        "    for file in unused_files:\n",
        "        if not os.path.exists(file):\n",
        "            print(f\"[Delete Unused] {file} : File Not Found\")\n",
        "            continue\n",
        "        !rm {file}\n",
        "        print(f\"[Delete Unused] {file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD8gE6vTxc0b"
      },
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MzKqYILwgtQ"
      },
      "outputs": [],
      "source": [
        "config = import_config()    # Input yaml config file\n",
        "# dict_print(config)\n",
        "\n",
        "gdrive = config[\"gdrive\"]\n",
        "civitai_api_key = config[\"civitai_api_key\"]\n",
        "\n",
        "install_requerements()\n",
        "# run_ngrok_service(config[\"ngrok_token\"])\n",
        "\n",
        "if gdrive:\n",
        "    output_path = gdrive.get(\"output_path\", output_path)\n",
        "    mount_drive()\n",
        "    !mkdir -p {output_path}\n",
        "    if gdrive.get(\"enable_restore_assets\", False):\n",
        "        for file in gdrive.get(\"backup_assets\", []):\n",
        "            copy_assets(\n",
        "                from_dir=file[\"backup_dir\"] + \"/*\",\n",
        "                to_dir=file[\"working_dir\"]\n",
        "            )\n",
        "\n",
        "for model in config.get(\"models\", []):\n",
        "    batch_download(model[\"models\"], model[\"dir\"])\n",
        "\n",
        "for embedding in config.get(\"embeddings\", []):\n",
        "    batch_download(embedding[\"embeddings\"], embedding[\"dir\"])\n",
        "\n",
        "for lora in config.get(\"loras\", []):\n",
        "    batch_download(lora[\"loras\"], lora[\"dir\"])\n",
        "\n",
        "print() # newline\n",
        "for preset in config.get(\"presets\", []):\n",
        "    generate_preset(preset[\"preset\"], preset[\"file_name\"])\n",
        "\n",
        "print() # newline\n",
        "for style in config.get(\"styles\", []):\n",
        "    generate_style(style[\"styles\"], style[\"file_name\"])\n",
        "\n",
        "print() # newline\n",
        "for wildcard in config.get(\"wildcards\", []):\n",
        "    if isinstance(wildcard[\"wildcard\"], list):\n",
        "        wildcard[\"wildcard\"] = \"\\n\".join(wildcard[\"wildcard\"])\n",
        "    generate_wildcard(wildcard[\"wildcard\"], wildcard[\"file_name\"])\n",
        "\n",
        "if \"unused\" in config and isinstance(config[\"unused\"], list):\n",
        "    print() # newline\n",
        "    delete_unused_files(config[\"unused\"])\n",
        "\n",
        "\n",
        "if gdrive and gdrive.get(\"enable_backup_assets\", False):\n",
        "    for file in gdrive.get(\"backup_assets\", []):\n",
        "        copy_assets(\n",
        "            from_dir=file[\"working_dir\"] + \"/*\",\n",
        "            to_dir=file[\"backup_dir\"]\n",
        "        )\n",
        "\n",
        "models_storage_stats()\n",
        "\n",
        "preset = config[\"preset\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ps8VBuGuOk_l"
      },
      "outputs": [],
      "source": [
        "print(\"preset\", preset)\n",
        "print(\"output_path\", output_path)\n",
        "\n",
        "!python entry_with_update.py \\\n",
        "    --share \\\n",
        "    --always-high-vram \\\n",
        "    --preset {preset} \\\n",
        "    --output-path {output_path}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
